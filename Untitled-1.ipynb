{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "3435c8a58a6da1c5f3ad4d180e4fa3b18a8bae647645cedfda491294259667a8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "字典值 : [('Google', 'www.google.com'), ('Runoob', 'www.runoob.com'), ('taobao', 'www.taobao.com')]\nGoogle www.google.com\nRunoob www.runoob.com\ntaobao www.taobao.com\n"
     ]
    }
   ],
   "source": [
    "dict = {'Google': 'www.google.com', 'Runoob': 'www.runoob.com', 'taobao': 'www.taobao.com'}\n",
    " \n",
    "print(\"字典值 :\",list(dict.items()))\n",
    " \n",
    "# 遍历字典列表\n",
    "for key,value in  dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(dic,bow):\n",
    "    tfdic = {}\n",
    "    bowcount = len(bow)\n",
    "    for word,count in dic.items():\n",
    "        tfdi[word] = count/float(bowcount)\n",
    "    return tfdic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['This is sentence one. ',\n",
       " 'This is sentence two? ',\n",
       " 'And this is sentence three! ',\n",
       " 'what is this? ',\n",
       " 'But it is? ',\n",
       " 'My email is U.S.A@fudan.edu.cn. ']"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "unsp = \"This is sentence one. This is sentence two? And this is sentence three! what is this? But it is? My email is U.S.A@fudan.edu.cn. \"\n",
    "splited = list(filter(None,re.split(\"([A-Z]+[^?.!]+[.?!] )\",unsp)))\n",
    "splited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"database.txt\",\"r\") as fp:\n",
    "    database = fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sents(unsplited):\n",
    "    splited = list(map(lambda x:list(filter(None,re.split(\"([A-Z]+[^?.!]+[.?!] )\",x))),unsplited))\n",
    "    return splited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "526"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "len(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'sentence',\n",
       " 'one',\n",
       " ',',\n",
       " 'but',\n",
       " 'this',\n",
       " 'is',\n",
       " 'sentence',\n",
       " 'two',\n",
       " '.',\n",
       " 'My',\n",
       " 'email',\n",
       " 'adress',\n",
       " 'is',\n",
       " 'U.S.A@fudan.edu.cn']"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "split1 = \"This is sentence one, but this is sentence two. My email adress is U.S.A@fudan.edu.cn\"\n",
    "list(filter(None,re.split(\" |([.!?,]) \",split1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['This is sentence one. ',\n",
       "  'This is sentence two? ',\n",
       "  'And this is sentence three! ',\n",
       "  'what is this? ',\n",
       "  'But it is? ',\n",
       "  'My email is U.S.A@fudan.edu.cn. '],\n",
       " ['This is sentence one. ',\n",
       "  'This is sentence two? ',\n",
       "  'And this is sentence three! ',\n",
       "  'what is this? ',\n",
       "  'But it is? ',\n",
       "  'My email is U.S.A@fudan.edu.cn. ']]"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "dsp = [splited,splited]\n",
    "dsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['This', 'is', 'sentence', 'one', '.'],\n",
       " ['This', 'is', 'sentence', 'two', '?'],\n",
       " ['And', 'this', 'is', 'sentence', 'three', '!'],\n",
       " ['what', 'is', 'this', '?'],\n",
       " ['But', 'it', 'is', '?'],\n",
       " ['My', 'email', 'is', 'U.S.A@fudan.edu.cn', '.']]"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "for item in dsp:\n",
    "    a = list(map(lambda x:list(filter(None,re.split(\" |([.!?,]) \",x))),item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[['This', 'is', 'sentence', 'one', '.'],\n",
       "  ['This', 'is', 'sentence', 'two', '?'],\n",
       "  ['And', 'this', 'is', 'sentence', 'three', '!'],\n",
       "  ['what', 'is', 'this', '?'],\n",
       "  ['But', 'it', 'is', '?'],\n",
       "  ['My', 'email', 'is', 'U.S.A@fudan.edu.cn', '.']],\n",
       " [['This', 'is', 'sentence', 'one', '.'],\n",
       "  ['This', 'is', 'sentence', 'two', '?'],\n",
       "  ['And', 'this', 'is', 'sentence', 'three', '!'],\n",
       "  ['what', 'is', 'this', '?'],\n",
       "  ['But', 'it', 'is', '?'],\n",
       "  ['My', 'email', 'is', 'U.S.A@fudan.edu.cn', '.']]]"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "list(map(lambda y:list(map(lambda x:list(filter(None,re.split(\" |([.!?,]) \",x))),y)),dsp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['Ophthalmic',\n",
       "  'gene',\n",
       "  'therapy',\n",
       "  'is',\n",
       "  'an',\n",
       "  'intellectual',\n",
       "  'and',\n",
       "  'intentional',\n",
       "  'manipulation',\n",
       "  'of',\n",
       "  'desired',\n",
       "  'gene',\n",
       "  'expression',\n",
       "  'into',\n",
       "  'the',\n",
       "  'specific',\n",
       "  'cells',\n",
       "  'of',\n",
       "  'an',\n",
       "  'eye',\n",
       "  'for',\n",
       "  'the',\n",
       "  'treatment',\n",
       "  'of',\n",
       "  'ophthalmic',\n",
       "  '(ocular)',\n",
       "  'genetic',\n",
       "  'dystrophies',\n",
       "  'and',\n",
       "  'pathological',\n",
       "  'conditions',\n",
       "  '.'],\n",
       " ['Exogenous',\n",
       "  'nucleic',\n",
       "  'acids',\n",
       "  'such',\n",
       "  'as',\n",
       "  'DNA',\n",
       "  ',',\n",
       "  'small',\n",
       "  'interfering',\n",
       "  'RNA',\n",
       "  ',',\n",
       "  'micro',\n",
       "  'RNA',\n",
       "  ',',\n",
       "  'and',\n",
       "  'so',\n",
       "  'on',\n",
       "  ',',\n",
       "  'are',\n",
       "  'used',\n",
       "  'for',\n",
       "  'the',\n",
       "  'purpose',\n",
       "  'of',\n",
       "  'managing',\n",
       "  'expression',\n",
       "  'of',\n",
       "  'the',\n",
       "  'desired',\n",
       "  'therapeutic',\n",
       "  'proteins',\n",
       "  'in',\n",
       "  'ocular',\n",
       "  'tissues',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'delivery',\n",
       "  'of',\n",
       "  'unprotected',\n",
       "  'nucleic',\n",
       "  'acids',\n",
       "  'into',\n",
       "  'the',\n",
       "  'cells',\n",
       "  'is',\n",
       "  'limited',\n",
       "  'because',\n",
       "  'of',\n",
       "  'exogenous',\n",
       "  'and',\n",
       "  'endogenous',\n",
       "  'degradation',\n",
       "  'modalities',\n",
       "  '.'],\n",
       " ['Nanotechnology',\n",
       "  ',',\n",
       "  'a',\n",
       "  'promising',\n",
       "  'and',\n",
       "  'sophisticated',\n",
       "  'cutting',\n",
       "  'edge',\n",
       "  'tool',\n",
       "  ',',\n",
       "  'works',\n",
       "  'as',\n",
       "  'a',\n",
       "  'protective',\n",
       "  'shelter',\n",
       "  'for',\n",
       "  'these',\n",
       "  'therapeutic',\n",
       "  'nucleic',\n",
       "  'acids',\n",
       "  '.'],\n",
       " ['They',\n",
       "  'can',\n",
       "  'be',\n",
       "  'safely',\n",
       "  'delivered',\n",
       "  'to',\n",
       "  'the',\n",
       "  'required',\n",
       "  'cells',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'modulate',\n",
       "  'anticipated',\n",
       "  'protein',\n",
       "  'expression',\n",
       "  '.'],\n",
       " ['To',\n",
       "  'this',\n",
       "  'end',\n",
       "  ',',\n",
       "  'nanotechnology',\n",
       "  'is',\n",
       "  'seen',\n",
       "  'as',\n",
       "  'a',\n",
       "  'potential',\n",
       "  'and',\n",
       "  'promising',\n",
       "  'strategy',\n",
       "  'in',\n",
       "  'the',\n",
       "  'field',\n",
       "  'of',\n",
       "  'ocular',\n",
       "  'gene',\n",
       "  'delivery',\n",
       "  '.'],\n",
       " ['This',\n",
       "  'review',\n",
       "  'focused',\n",
       "  'on',\n",
       "  'current',\n",
       "  'nanotechnology',\n",
       "  'modalities',\n",
       "  'and',\n",
       "  'other',\n",
       "  'promising',\n",
       "  'nonviral',\n",
       "  'strategies',\n",
       "  'being',\n",
       "  'used',\n",
       "  'to',\n",
       "  'deliver',\n",
       "  'therapeutic',\n",
       "  'genes',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'treat',\n",
       "  'various',\n",
       "  'devastating',\n",
       "  'ocular',\n",
       "  'diseases',\n",
       "  '.'],\n",
       " ['WIREs', 'Nanomed', 'Nanobiotechnol', '2015', ',', '8:160-174', '.'],\n",
       " ['doi:', '10.1002/wnan.1356'],\n",
       " ['For',\n",
       "  'further',\n",
       "  'resources',\n",
       "  'related',\n",
       "  'to',\n",
       "  'this',\n",
       "  'article',\n",
       "  ',',\n",
       "  'please',\n",
       "  'visit',\n",
       "  'the',\n",
       "  'WIREs',\n",
       "  'website',\n",
       "  '.'],\n",
       " ['+86-15393656331\\n']]"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "with open(\"database splited2.txt\",\"r\") as fp:\n",
    "    database_splited2 = eval(fp.readline())\n",
    "\n",
    "sp_1 = database_splited2[-1]\n",
    "sp_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = sp_1[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_rep = list(map(lambda z: list(map(lambda y: list(map(lambda x: re.sub(\"\\+86-\\d{9,12}|1\\d{9,12}\",\"(phone)\",x),y)),z)),database_splited2))\n",
    "email_rep = list(map(lambda z: list(map(lambda y: list(map(lambda x: re.sub(\"(\\w+@\\w+\\.com)|(\\w+@\\w+\\.+\\w+\\.cn)\",\"(email)\",x),y)),z)),phone_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[1], [2], [3], [4], [5], [6], [1, 2]]"
      ]
     },
     "metadata": {},
     "execution_count": 159
    }
   ],
   "source": [
    "li=[[[1],[2]],[[3],[4]],[[5],[6],[1,2]]]\n",
    "[j for i in li for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'.', 'of'}"
      ]
     },
     "metadata": {},
     "execution_count": 216
    }
   ],
   "source": [
    "flattern = list(map(lambda x:[j for i in x for j in i],email_rep))\n",
    "flattern_withoutcap = eval(re.sub(\"[A-Z]\",lambda x:chr(ord(x.group(0))^32),str(flattern)))\n",
    "base_set = [set(i) for i in flattern_withoutcap]\n",
    "stop = set.intersection(*base_set)\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "metadata": {},
     "execution_count": 221
    }
   ],
   "source": [
    "sentence1 = flattern_withoutcap[1]\n",
    "len(sentence1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "def counter(sentence):\n",
    "    return Counter(sentence).most_common(math.ceil(len(sentence)*0.9)) \n",
    "top25 = counter(sentence1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(sen):\n",
    "    top25 = counter(sen)\n",
    "    tf = [[j[0],j[1]/len(sen)] for j in top25]\n",
    "    return tf\n",
    "tf(sentence1)\n",
    "possibletf = list(map(tf,flattern_withoutcap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[49, 13, 46]"
      ]
     },
     "metadata": {},
     "execution_count": 242
    }
   ],
   "source": [
    "tf(flattern_withoutcap[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "233.8403041825095"
      ]
     },
     "metadata": {},
     "execution_count": 262
    }
   ],
   "source": [
    "tf(flattern_withoutcap[109])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['the', 0.15384615384615385]]"
      ]
     },
     "metadata": {},
     "execution_count": 246
    }
   ],
   "source": [
    "n = list(map(len,flattern_withoutcap))\n",
    "sum(n)/len(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['sleep', 0.06545454545454546],\n",
       " ['of', 0.05090909090909091],\n",
       " [',', 0.05090909090909091],\n",
       " ['the', 0.04],\n",
       " ['and', 0.04],\n",
       " ['.', 0.03272727272727273],\n",
       " ['in', 0.02909090909090909],\n",
       " ['women', 0.01818181818181818],\n",
       " ['percentage', 0.014545454545454545],\n",
       " ['gender', 0.01090909090909091],\n",
       " ['a', 0.01090909090909091],\n",
       " ['general', 0.01090909090909091],\n",
       " ['population', 0.01090909090909091],\n",
       " ['external', 0.01090909090909091],\n",
       " ['night', 0.01090909090909091],\n",
       " ['young', 0.01090909090909091],\n",
       " ['with', 0.01090909090909091],\n",
       " ['men', 0.01090909090909091],\n",
       " ['to', 0.01090909090909091],\n",
       " ['this', 0.007272727272727273],\n",
       " ['were', 0.007272727272727273],\n",
       " ['(i)', 0.007272727272727273],\n",
       " ['differences', 0.007272727272727273],\n",
       " ['(ii)', 0.007272727272727273],\n",
       " ['menopause', 0.007272727272727273],\n",
       " ['on', 0.007272727272727273],\n",
       " ['stressors', 0.007272727272727273],\n",
       " ['without', 0.007272727272727273],\n",
       " ['complaints', 0.007272727272727273],\n",
       " ['from', 0.007272727272727273],\n",
       " ['that', 0.007272727272727273],\n",
       " ['healthy', 0.007272727272727273],\n",
       " ['was', 0.007272727272727273],\n",
       " ['by', 0.007272727272727273],\n",
       " ['blood', 0.007272727272727273],\n",
       " ['compared', 0.007272727272727273],\n",
       " ['significantly', 0.007272727272727273],\n",
       " ['higher', 0.007272727272727273],\n",
       " ['time', 0.007272727272727273],\n",
       " ['lower', 0.007272727272727273],\n",
       " ['stage', 0.007272727272727273],\n",
       " ['1', 0.007272727272727273],\n",
       " ['also', 0.007272727272727273],\n",
       " [\"women's\", 0.007272727272727273],\n",
       " ['aims', 0.0036363636363636364],\n",
       " ['study', 0.0036363636363636364],\n",
       " ['to:', 0.0036363636363636364],\n",
       " ['assess', 0.0036363636363636364],\n",
       " ['objective', 0.0036363636363636364],\n",
       " ['patterns', 0.0036363636363636364],\n",
       " ['sample;', 0.0036363636363636364],\n",
       " ['evaluate', 0.0036363636363636364],\n",
       " ['effects', 0.0036363636363636364],\n",
       " ['hormone', 0.0036363636363636364],\n",
       " ['treatment', 0.0036363636363636364],\n",
       " ['(ht)', 0.0036363636363636364],\n",
       " ['same', 0.0036363636363636364],\n",
       " ['cohort;', 0.0036363636363636364],\n",
       " ['(iii)', 0.0036363636363636364],\n",
       " ['examine', 0.0036363636363636364],\n",
       " ['resilience', 0.0036363636363636364],\n",
       " ['towards', 0.0036363636363636364],\n",
       " ['participants', 0.0036363636363636364],\n",
       " ['1324', 0.0036363636363636364],\n",
       " ['subjects', 0.0036363636363636364],\n",
       " ['recruited', 0.0036363636363636364],\n",
       " ['central', 0.0036363636363636364],\n",
       " ['pennsylvania', 0.0036363636363636364],\n",
       " ['spent', 0.0036363636363636364],\n",
       " ['one', 0.0036363636363636364],\n",
       " ['laboratory', 0.0036363636363636364],\n",
       " ['66', 0.0036363636363636364],\n",
       " ['volunteers', 0.0036363636363636364],\n",
       " ['whose', 0.0036363636363636364],\n",
       " ['disturbed', 0.0036363636363636364],\n",
       " ['during', 0.0036363636363636364],\n",
       " ['four', 0.0036363636363636364],\n",
       " ['an', 0.0036363636363636364],\n",
       " ['stressor', 0.0036363636363636364],\n",
       " ['i.e', 0.0036363636363636364],\n",
       " ['24-h', 0.0036363636363636364],\n",
       " ['drawing', 0.0036363636363636364],\n",
       " ['(average', 0.0036363636363636364],\n",
       " ['nights', 0.0036363636363636364],\n",
       " ['2', 0.0036363636363636364],\n",
       " ['3', 0.0036363636363636364],\n",
       " ['versus', 0.0036363636363636364],\n",
       " ['4)', 0.0036363636363636364],\n",
       " ['sample', 0.0036363636363636364],\n",
       " ['had', 0.0036363636363636364],\n",
       " ['slow', 0.0036363636363636364],\n",
       " ['wave', 0.0036363636363636364],\n",
       " ['absence', 0.0036363636363636364],\n",
       " ['ht', 0.0036363636363636364],\n",
       " ['associated', 0.0036363636363636364],\n",
       " ['prolonged', 0.0036363636363636364],\n",
       " ['latency', 0.0036363636363636364],\n",
       " ['decreased', 0.0036363636363636364],\n",
       " ['deep', 0.0036363636363636364],\n",
       " ['finally', 0.0036363636363636364],\n",
       " ['experienced', 0.0036363636363636364],\n",
       " ['less', 0.0036363636363636364],\n",
       " ['disturbance', 0.0036363636363636364],\n",
       " ['because', 0.0036363636363636364],\n",
       " ['draws', 0.0036363636363636364],\n",
       " ['as', 0.0036363636363636364],\n",
       " ['indicated', 0.0036363636363636364],\n",
       " ['smaller', 0.0036363636363636364],\n",
       " ['change', 0.0036363636363636364],\n",
       " ['per', 0.0036363636363636364],\n",
       " ['cent', 0.0036363636363636364],\n",
       " ['these', 0.0036363636363636364],\n",
       " ['findings', 0.0036363636363636364],\n",
       " ['suggest', 0.0036363636363636364],\n",
       " ['objectively', 0.0036363636363636364],\n",
       " ['better', 0.0036363636363636364],\n",
       " ['across', 0.0036363636363636364],\n",
       " ['age', 0.0036363636363636364],\n",
       " ['than', 0.0036363636363636364],\n",
       " ['is', 0.0036363636363636364],\n",
       " ['more', 0.0036363636363636364],\n",
       " ['resistant', 0.0036363636363636364],\n",
       " ['gonadal', 0.0036363636363636364],\n",
       " ['hormones', 0.0036363636363636364],\n",
       " ['exert', 0.0036363636363636364],\n",
       " ['beneficial', 0.0036363636363636364],\n",
       " ['effect', 0.0036363636363636364],\n",
       " ['dimorphism', 0.0036363636363636364],\n",
       " ['regulation', 0.0036363636363636364],\n",
       " ['may', 0.0036363636363636364],\n",
       " ['have', 0.0036363636363636364],\n",
       " ['been', 0.0036363636363636364],\n",
       " ['protect', 0.0036363636363636364],\n",
       " ['demands', 0.0036363636363636364],\n",
       " ['infant', 0.0036363636363636364],\n",
       " ['child', 0.0036363636363636364],\n",
       " ['care', 0.0036363636363636364],\n",
       " ['part', 0.0036363636363636364],\n",
       " ['might', 0.0036363636363636364],\n",
       " ['contribute', 0.0036363636363636364],\n",
       " ['cardiovascular', 0.0036363636363636364],\n",
       " ['risks', 0.0036363636363636364],\n",
       " ['greater', 0.0036363636363636364],\n",
       " ['longevity', 0.0036363636363636364],\n",
       " ['(email)\\n', 0.0036363636363636364]]"
      ]
     },
     "metadata": {},
     "execution_count": 269
    }
   ],
   "source": [
    "list(filter(lambda x:x<50,list(map(len,flattern_withoutcap))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "allword = [j for i in base_set for j in i]\n",
    "allwordcount = Counter(allword).most_common(len(allword))\n",
    "transpose = [[row[i] for row in allwordcount] for i in range(2)]\n",
    "IDFdict = dict(zip(*transpose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "metadata": {},
     "execution_count": 349
    }
   ],
   "source": [
    "def idffind(sen):\n",
    "    return([[i,IDFdict[i]] for i in sen])\n",
    "possibleIDF = list(map(idffind,base_set))\n",
    "len(possibleIDF[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "possibleTFtran = [[row[i] for row in possibletf[2]] for i in range(2)]\n",
    "TFdict = dict(zip(*possibleTFtran))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 352
    }
   ],
   "source": [
    "[len(possibleIDF[i]) for i in range(len(possibleIDF))] == [len(possibletf[i]) for i in range(len(possibletf))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takefirst(elem):\n",
    "    return elem[0]\n",
    "def sortfirst(sen):\n",
    "    sen.sort(key=takefirst)\n",
    "    return sen\n",
    "IDFsorted = list(map(sortfirst,possibleIDF))\n",
    "TFsorted = list(map(sortfirst,possibletf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['(phone)\\n', 247],\n",
       " [',', 509],\n",
       " ['.', 526],\n",
       " ['a', 490],\n",
       " ['addition', 36],\n",
       " ['alleviating', 1],\n",
       " ['also', 124],\n",
       " ['amxiolytic', 1],\n",
       " ['and', 522],\n",
       " ['animal', 18],\n",
       " ['anxiolytic', 1],\n",
       " ['are', 238],\n",
       " ['as', 269],\n",
       " ['assays', 9],\n",
       " ['available', 39],\n",
       " ['be', 214],\n",
       " ['been', 126],\n",
       " ['behavioral', 11],\n",
       " ['behaviors', 5],\n",
       " ['between', 171],\n",
       " ['buspirone', 1],\n",
       " ['but', 107],\n",
       " ['can', 127],\n",
       " ['causes', 19],\n",
       " ['cell-based', 2],\n",
       " ['chlordiazepoxide', 1],\n",
       " ['classic', 3],\n",
       " ['cognitive', 12],\n",
       " ['complex', 31],\n",
       " ['compounds', 9],\n",
       " ['crucial', 16],\n",
       " ['determine', 51],\n",
       " ['developed', 40],\n",
       " ['development', 43],\n",
       " ['diazepam', 1],\n",
       " ['diving', 1],\n",
       " ['drug', 34],\n",
       " ['drugs', 21],\n",
       " ['due', 51],\n",
       " ['economical', 2],\n",
       " ['effects', 57],\n",
       " ['efficacy', 32],\n",
       " ['efficient', 9],\n",
       " ['efficiently', 3],\n",
       " ['elaborate', 1],\n",
       " ['enhancement', 6],\n",
       " ['enhancing', 8],\n",
       " ['for', 424],\n",
       " ['function', 45],\n",
       " ['functional', 36],\n",
       " ['good', 22],\n",
       " ['has', 162],\n",
       " ['have', 153],\n",
       " ['helping', 1],\n",
       " ['however', 115],\n",
       " ['humans', 9],\n",
       " ['impairments', 3],\n",
       " ['in', 506],\n",
       " ['indication', 4],\n",
       " ['intermediate', 12],\n",
       " ['interpreted', 4],\n",
       " ['is', 371],\n",
       " ['it', 111],\n",
       " ['lab', 3],\n",
       " ['learning', 5],\n",
       " ['makes', 6],\n",
       " ['mammalian', 10],\n",
       " ['manner', 10],\n",
       " ['mechanisms', 25],\n",
       " ['memory', 10],\n",
       " ['model', 47],\n",
       " ['models', 36],\n",
       " ['molecular', 77],\n",
       " ['much', 16],\n",
       " ['must', 12],\n",
       " ['nervous', 9],\n",
       " ['neural', 9],\n",
       " ['neurobehavioral', 2],\n",
       " ['neuromolecular', 1],\n",
       " ['new', 77],\n",
       " ['nicotine', 1],\n",
       " ['nicotinic-induced', 1],\n",
       " ['not', 165],\n",
       " ['novel', 40],\n",
       " ['of', 526],\n",
       " ['our', 117],\n",
       " ['outstanding', 1],\n",
       " ['particular', 12],\n",
       " ['pharmacology', 3],\n",
       " ['possible', 36],\n",
       " ['potential', 52],\n",
       " ['provide', 45],\n",
       " ['psychoactive', 2],\n",
       " ['quick', 1],\n",
       " ['receptor', 28],\n",
       " ['reduction', 26],\n",
       " ['relatively', 10],\n",
       " ['repertoire', 1],\n",
       " ['response', 47],\n",
       " ['rodent', 3],\n",
       " ['screen', 4],\n",
       " ['screening', 13],\n",
       " ['sensitive', 12],\n",
       " ['series', 25],\n",
       " ['shown', 29],\n",
       " ['similar', 51],\n",
       " ['stress', 16],\n",
       " ['stress-related', 1],\n",
       " ['studies', 84],\n",
       " ['system', 45],\n",
       " ['tank', 2],\n",
       " ['task', 9],\n",
       " ['test', 34],\n",
       " ['tests', 14],\n",
       " ['the', 523],\n",
       " ['them', 21],\n",
       " ['therapeutic', 33],\n",
       " ['they', 40],\n",
       " ['three-chamber', 1],\n",
       " ['to', 504],\n",
       " ['tools', 13],\n",
       " ['translational', 5],\n",
       " ['treatments', 13],\n",
       " ['use', 82],\n",
       " ['useful', 19],\n",
       " ['valid', 6],\n",
       " ['validated', 5],\n",
       " ['valuable', 7],\n",
       " ['variety', 10],\n",
       " ['vitro', 28],\n",
       " ['was', 325],\n",
       " ['we', 264],\n",
       " ['which', 153],\n",
       " ['zebrafish', 1]]"
      ]
     },
     "metadata": {},
     "execution_count": 378
    }
   ],
   "source": [
    "IDFsorted[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['(phone)\\n', 0.0035460992907801418],\n",
       " [',', 0.024822695035460994],\n",
       " ['.', 0.03900709219858156],\n",
       " ['a', 0.028368794326241134],\n",
       " ['addition', 0.0035460992907801418],\n",
       " ['alleviating', 0.0070921985815602835],\n",
       " ['also', 0.0035460992907801418],\n",
       " ['amxiolytic', 0.0035460992907801418],\n",
       " ['and', 0.04964539007092199],\n",
       " ['animal', 0.0035460992907801418],\n",
       " ['anxiolytic', 0.0070921985815602835],\n",
       " ['are', 0.0070921985815602835],\n",
       " ['as', 0.01773049645390071],\n",
       " ['assays', 0.0035460992907801418],\n",
       " ['available', 0.0035460992907801418],\n",
       " ['be', 0.01773049645390071],\n",
       " ['been', 0.0035460992907801418],\n",
       " ['behavioral', 0.010638297872340425],\n",
       " ['behaviors', 0.0035460992907801418],\n",
       " ['between', 0.0035460992907801418],\n",
       " ['buspirone', 0.0035460992907801418],\n",
       " ['but', 0.0035460992907801418],\n",
       " ['can', 0.02127659574468085],\n",
       " ['causes', 0.0035460992907801418],\n",
       " ['cell-based', 0.0035460992907801418],\n",
       " ['chlordiazepoxide', 0.0035460992907801418],\n",
       " ['classic', 0.0035460992907801418],\n",
       " ['cognitive', 0.01773049645390071],\n",
       " ['complex', 0.0035460992907801418],\n",
       " ['compounds', 0.0035460992907801418],\n",
       " ['crucial', 0.0070921985815602835],\n",
       " ['determine', 0.010638297872340425],\n",
       " ['developed', 0.0035460992907801418],\n",
       " ['development', 0.0035460992907801418],\n",
       " ['diazepam', 0.0035460992907801418],\n",
       " ['diving', 0.0035460992907801418],\n",
       " ['drug', 0.010638297872340425],\n",
       " ['drugs', 0.010638297872340425],\n",
       " ['due', 0.0035460992907801418],\n",
       " ['economical', 0.0035460992907801418],\n",
       " ['effects', 0.014184397163120567],\n",
       " ['efficacy', 0.0035460992907801418],\n",
       " ['efficient', 0.0070921985815602835],\n",
       " ['efficiently', 0.0035460992907801418],\n",
       " ['elaborate', 0.0035460992907801418],\n",
       " ['enhancement', 0.0070921985815602835],\n",
       " ['enhancing', 0.0070921985815602835],\n",
       " ['for', 0.028368794326241134],\n",
       " ['function', 0.0035460992907801418],\n",
       " ['functional', 0.0035460992907801418],\n",
       " ['good', 0.0035460992907801418],\n",
       " ['has', 0.0070921985815602835],\n",
       " ['have', 0.0070921985815602835],\n",
       " ['helping', 0.010638297872340425],\n",
       " ['however', 0.0035460992907801418],\n",
       " ['humans', 0.0035460992907801418],\n",
       " ['impairments', 0.0035460992907801418],\n",
       " ['in', 0.03546099290780142],\n",
       " ['indication', 0.0035460992907801418],\n",
       " ['intermediate', 0.0035460992907801418],\n",
       " ['interpreted', 0.0035460992907801418],\n",
       " ['is', 0.0035460992907801418],\n",
       " ['it', 0.0035460992907801418],\n",
       " ['lab', 0.0035460992907801418],\n",
       " ['learning', 0.0035460992907801418],\n",
       " ['makes', 0.0035460992907801418],\n",
       " ['mammalian', 0.0035460992907801418],\n",
       " ['manner', 0.0035460992907801418],\n",
       " ['mechanisms', 0.010638297872340425],\n",
       " ['memory', 0.0035460992907801418],\n",
       " ['model', 0.010638297872340425],\n",
       " ['models', 0.014184397163120567],\n",
       " ['molecular', 0.0035460992907801418],\n",
       " ['much', 0.0035460992907801418],\n",
       " ['must', 0.0035460992907801418],\n",
       " ['nervous', 0.0035460992907801418],\n",
       " ['neural', 0.0035460992907801418],\n",
       " ['neurobehavioral', 0.0035460992907801418],\n",
       " ['neuromolecular', 0.0035460992907801418],\n",
       " ['new', 0.0035460992907801418],\n",
       " ['nicotine', 0.0070921985815602835],\n",
       " ['nicotinic-induced', 0.0035460992907801418],\n",
       " ['not', 0.0035460992907801418],\n",
       " ['novel', 0.0035460992907801418],\n",
       " ['of', 0.028368794326241134],\n",
       " ['our', 0.0035460992907801418],\n",
       " ['outstanding', 0.0035460992907801418],\n",
       " ['particular', 0.0035460992907801418],\n",
       " ['pharmacology', 0.0035460992907801418],\n",
       " ['possible', 0.0035460992907801418],\n",
       " ['potential', 0.0035460992907801418],\n",
       " ['provide', 0.010638297872340425],\n",
       " ['psychoactive', 0.0035460992907801418],\n",
       " ['quick', 0.0035460992907801418],\n",
       " ['receptor', 0.0035460992907801418],\n",
       " ['reduction', 0.0035460992907801418],\n",
       " ['relatively', 0.0035460992907801418],\n",
       " ['repertoire', 0.0035460992907801418],\n",
       " ['response', 0.010638297872340425],\n",
       " ['rodent', 0.0035460992907801418],\n",
       " ['screen', 0.0070921985815602835],\n",
       " ['screening', 0.0035460992907801418],\n",
       " ['sensitive', 0.014184397163120567],\n",
       " ['series', 0.0035460992907801418],\n",
       " ['shown', 0.0070921985815602835],\n",
       " ['similar', 0.0035460992907801418],\n",
       " ['stress', 0.014184397163120567],\n",
       " ['stress-related', 0.0035460992907801418],\n",
       " ['studies', 0.0035460992907801418],\n",
       " ['system', 0.0035460992907801418],\n",
       " ['tank', 0.0035460992907801418],\n",
       " ['task', 0.0035460992907801418],\n",
       " ['test', 0.010638297872340425],\n",
       " ['tests', 0.0070921985815602835],\n",
       " ['the', 0.028368794326241134],\n",
       " ['them', 0.0035460992907801418],\n",
       " ['therapeutic', 0.0035460992907801418],\n",
       " ['they', 0.0070921985815602835],\n",
       " ['three-chamber', 0.0035460992907801418],\n",
       " ['to', 0.0425531914893617],\n",
       " ['tools', 0.0035460992907801418],\n",
       " ['translational', 0.0035460992907801418],\n",
       " ['treatments', 0.0035460992907801418],\n",
       " ['use', 0.0035460992907801418],\n",
       " ['useful', 0.010638297872340425],\n",
       " ['valid', 0.0035460992907801418],\n",
       " ['validated', 0.0035460992907801418],\n",
       " ['valuable', 0.0035460992907801418],\n",
       " ['variety', 0.0035460992907801418],\n",
       " ['vitro', 0.0035460992907801418],\n",
       " ['was', 0.0070921985815602835],\n",
       " ['we', 0.0035460992907801418],\n",
       " ['which', 0.0070921985815602835],\n",
       " ['zebrafish', 0.01773049645390071]]"
      ]
     },
     "metadata": {},
     "execution_count": 379
    }
   ],
   "source": [
    "TFsorted[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'log' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-380-78aa16009595>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'log' is not defined"
     ]
    }
   ],
   "source": [
    "log(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IDF(sen):\n",
    "    return [[i[0],math.log(len(base_set)/(1+i[1]))] for i in sen]\n",
    "\n",
    "TRUEIDF = list(map(IDF,possibleIDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Object `TF` not found.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = [[\"a\",33],[\"b\",2]]\n",
    "bb = [[\"a\",81],[\"b\",46]]\n",
    "def tfidf(a,b):\n",
    "    res = []\n",
    "    for i in range(len(a)):\n",
    "        res.append([a[i][0],a[i][1]*b[i][1]])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF = list(map(tfidf,TRUEIDF,TFsorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takesecond(elem):\n",
    "    return elem[1]\n",
    "def sortsecond(sen):\n",
    "    sen.sort(key=takesecond,reverse = True)\n",
    "    return sen\n",
    "TFIDFsorted = list(map(sortsecond,TFIDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take5(a):\n",
    "    return a[0:math.ceil(len(a)*0.05)]\n",
    "\n",
    "top5 = list(map(take5,TFIDFsorted))\n",
    "def extractword(a):\n",
    "    return [i[0] for i in a]\n",
    "onlyword = list(map(extractword,top5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['handwashing', 'soap', 'hands', 'water', 'maban', '%', 'county', 'refugees']"
      ]
     },
     "metadata": {},
     "execution_count": 447
    }
   ],
   "source": [
    "firstpass = email_rep[0]\n",
    "onlyword[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattern = list(map(lambda x:[j for i in x for j in i],email_rep))\n",
    "flattern_withoutcap = eval(re.sub(\"[A-Z]\",lambda x:chr(ord(x.group(0))^32),str(flattern)))\n",
    "base_set = [set(i) for i in flattern_withoutcap]\n",
    "stop = set.intersection(*base_set)\n",
    "\n",
    "def counter(sentence):\n",
    "    return Counter(sentence).most_common(math.ceil(len(sentence)*0.9)) \n",
    "\n",
    "def tf(sen):\n",
    "    top25 = counter(sen)\n",
    "    tf = [[j[0],j[1]/len(sen)] for j in top25]\n",
    "    return tf\n",
    "\n",
    "possibletf = list(map(tf,flattern_withoutcap))\n",
    "\n",
    "allword = [j for i in base_set for j in i]\n",
    "allwordcount = Counter(allword).most_common(len(allword))\n",
    "transpose = [[row[i] for row in allwordcount] for i in range(2)]\n",
    "IDFdict = dict(zip(*transpose))\n",
    "\n",
    "def idffind(sen):\n",
    "    return([[i,IDFdict[i]] for i in sen])\n",
    "possibleIDF = list(map(idffind,base_set))\n",
    "\n",
    "possibleTFtran = [[row[i] for row in possibletf[2]] for i in range(2)]\n",
    "TFdict = dict(zip(*possibleTFtran))\n",
    "\n",
    "def takefirst(elem):\n",
    "    return elem[0]\n",
    "def sortfirst(sen):\n",
    "    sen.sort(key=takefirst)\n",
    "    return sen\n",
    "IDFsorted = list(map(sortfirst,possibleIDF))\n",
    "TFsorted = list(map(sortfirst,possibletf))\n",
    "\n",
    "def IDF(sen):\n",
    "    return [[i[0],math.log(len(base_set)/(1+i[1]))] for i in sen]\n",
    "\n",
    "TRUEIDF = list(map(IDF,possibleIDF))\n",
    "\n",
    "def tfidf(a,b):\n",
    "    res = []\n",
    "    for i in range(len(a)):\n",
    "        res.append([a[i][0],a[i][1]*b[i][1]])\n",
    "    return res\n",
    "\n",
    "TFIDF = list(map(tfidf,TRUEIDF,TFsorted))\n",
    "\n",
    "def takesecond(elem):\n",
    "    return elem[1]\n",
    "def sortsecond(sen):\n",
    "    sen.sort(key=takesecond,reverse = True)\n",
    "    return sen\n",
    "\n",
    "TFIDFsorted = list(map(sortsecond,TFIDF))\n",
    "\n",
    "with open(\"TFIDF.txt\",\"w\") as fp:\n",
    "    fp.write(str(TFIDFsorted))\n",
    "\n",
    "def take5(a):\n",
    "    return a[0:math.ceil(len(a)*0.05)]\n",
    "\n",
    "top5 = list(map(take5,TFIDFsorted))\n",
    "def extractword(a):\n",
    "    return [i[0] for i in a]\n",
    "onlyword = list(map(extractword,top5))\n",
    "\n",
    "with open(\"top5.txt\",\"w\") as fp:\n",
    "    fp.write(str(onlyword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "allword = list(map(extractword,TFIDFsorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeset(x):\n",
    "    return [set(i) for i in x]\n",
    "sentenceset = list(map(makeset,email_rep))\n",
    "\n",
    "def ct(wordset,sentence):\n",
    "    t = 0\n",
    "    for i in wordset:\n",
    "        if i in sentence:\n",
    "            t = t+1\n",
    "    return t\n",
    "\n",
    "def senct(wordset,sentence):\n",
    "    return [[i,ct(wordset,sentence[i])] for i in range(len(sentence))]\n",
    "\n",
    "wordappearance = list(map(senct,onlyword,sentenceset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "wasorted = list(map(sortsecond,wordappearance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take25(a):\n",
    "    return a[0:math.ceil(len(a)*0.25)]\n",
    "topsen = list(map(take25,wasorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takef(a):\n",
    "    return [i[0] for i in a]\n",
    "topsennum = list(map(takef,topsen))"
   ]
  },
  {
   "source": [
    "def wordjoin(a):\n",
    "    return [\" \".join(a[i]) for i in range(len(a))]\n",
    "sentense_rep = list(map(wordjoin,email_rep))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 504,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TOPSEN(num,sen):\n",
    "    coll = []\n",
    "    for i in num:\n",
    "        coll.append(sen[i])\n",
    "    return coll\n",
    "REALTOPSEN = list(map(TOPSEN,topsennum,sentense_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinneighbour(sen): #对于一个元素为字符串的列表，把相邻字符串接起来作为短语\n",
    "    return [[sen[i],sen[i+1]] for i in range(len(sen)-1)]\n",
    "\n",
    "def parajoinneigh(lis): #对于一篇文章的所有句子做短语接合\n",
    "    return list(map(joinneighbour,lis))\n",
    "\n",
    "def captosmall(lis): #把所有字符大写变小写\n",
    "    return eval(re.sub(\"[A-Z]\",lambda x:chr(ord(x.group(0))^32),str(lis)))\n",
    "\n",
    "wordsmall = list(map(captosmall,email_rep)) #把初始分割文件的大写变小写\n",
    "\n",
    "datajoinneighbour = list(map(parajoinneigh,wordsmall)) #对所有文章的所有句子做短语接合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "metadata": {},
     "execution_count": 705
    }
   ],
   "source": [
    "def phrasefind(word,sen): #此函数用途是对一个都是短语的句子寻找关键短语\n",
    "    wordbase = word #先把所有按照得分排好序的单词放到一个列表里\n",
    "    localword = take5(wordbase) #取单词库的前5%\n",
    "    keyphrase = [1]\n",
    "    for pair in sen: #拿这个短语列表中的一个短语出来\n",
    "        if set(pair) < set(localword): #如果这个短语构成的集合为前5%单词的子集，说明这些单词可以构成关键短语\n",
    "            wordbase.remove(pair[0]) #从单词库中删除这个短语中的两个单词\n",
    "            wordbase.remove(pair[1])\n",
    "            localword = take5(wordbase) #在删后的单词库中再取前5%作为关键词集合\n",
    "            keyphrase = keyphrase.append(\" \".join(pair)) #将得到的关键短语放入列表\n",
    "    return keyphrase \n",
    "phrasefind(allword[0],datajoinneighbour[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "metadata": {},
     "execution_count": 708
    }
   ],
   "source": [
    "def kp(word,sent):\n",
    "    for sen in sent:\n",
    "        phrase = []\n",
    "        phrase = phrase + phrasefind(word,sen)\n",
    "    return phrase\n",
    "\n",
    "kp(allword[90],datajoinneighbour[90])\n",
    "#list(map(kp,allword,datajoinneighbour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "string index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-704-7e9e87e6d2b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtfen1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mallword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m140\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtfen2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatajoinneighbour\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m140\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtfen1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtfen1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-687-4e7446384e6a>\u001b[0m in \u001b[0;36mkp\u001b[1;34m(word, sent)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msen\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mphrase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mphrase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mphrase\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mphrasefind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mphrase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-649-848c914ef518>\u001b[0m in \u001b[0;36mphrasefind\u001b[1;34m(word, sen)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocalword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#如果这个短语构成的集合为前5%单词的子集，说明这些单词可以构成关键短语\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mwordbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#从单词库中删除这个短语中的两个单词\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mwordbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mlocalword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtake5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwordbase\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#在删后的单词库中再取前5%作为关键词集合\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mkeyphrase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeyphrase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#将得到的关键短语放入列表\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "tfen1 = allword[0:140]\n",
    "tfen2 = datajoinneighbour[0:140]\n",
    "list(map(kp,tfen1,tfen1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordbase = allword[0]\n",
    "first5 = take5(wordbase)\n",
    "localword = first5\n",
    "localphrase = []\n",
    "for pair in datajoinneighbour[0][0]:\n",
    "    if len(localphrase) < len(localword):\n",
    "        if set(pair) < set(localword):\n",
    "            wordbase.remove(pair[0])\n",
    "            wordbase.remove(pair[1])\n",
    "            localword = take5(wordbase)\n",
    "            localphrase = keyphrase.append(\" \".join(pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 639
    }
   ],
   "source": [
    "[]+[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}